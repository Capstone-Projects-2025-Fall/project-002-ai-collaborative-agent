// supabase/functions/task-delegator/index.ts

// --- Imports -----------------------------------------------------------------
import { serve } from "https://deno.land/std@0.224.0/http/server.ts";
import { load } from "https://deno.land/std@0.224.0/dotenv/mod.ts"; // [2025-10-09] NEW: load .env and export to Deno.env

// --- Environment --------------------------------------------------------------

// [2025-10-09] NEW: load supabase/.env, export=true puts keys into Deno.env
await load({
  envPath: new URL("../../.env", import.meta.url).pathname, // resolves supabase/.env
  export: true,
});

// [2025-10-09] NEW: support BOTH your custom names and OpenAI standard names
const AI_ENDPOINT =
  Deno.env.get("AI_ENDPOINT") ?? Deno.env.get("OPENAI_BASE_URL") ?? "";
const AI_KEY =
  Deno.env.get("AI_KEY") ?? Deno.env.get("OPENAI_API_KEY") ?? "";
const OPENAI_PROJECT =
  Deno.env.get("OPENAI_PROJECT") ?? Deno.env.get("OPENAI_PROJECT_ID") ?? "";

// [2025-10-09] NEW: default to 8000 so it matches your settings.json
const PORT = Number(Deno.env.get("PORT") ?? 8000);

// [2025-10-09] DEBUG LOGS: helpful while wiring things up
console.log("Loaded .env from supabase/.env");
console.log("AI_ENDPOINT:", AI_ENDPOINT || "(not set)");
console.log("AI_KEY set? ", !!AI_KEY);
console.log("OPENAI_PROJECT:", OPENAI_PROJECT || "(not set)");
console.log(`Listening on http://localhost:${PORT}/`);

// --- Types -------------------------------------------------------------------

type AITask = {
  title: string;
  description: string;
  type?: "Task" | "Story" | "Bug" | string;
  priority?: "Highest" | "High" | "Medium" | "Low" | string;
  labels?: string[];
  storyPoints?: number;
  acceptanceCriteria?: string[];
};

type AIBacklog = {
  projectName?: string;
  tasks: AITask[];
};

// --- Utilities ----------------------------------------------------------------

// [2025-10-09] NEW: Basic CORS helper so curl / webview can talk to this server
function corsHeaders() {
  return {
    "Access-Control-Allow-Origin": "*",
    "Access-Control-Allow-Methods": "POST, OPTIONS",
    "Access-Control-Allow-Headers": "Content-Type, Authorization",
  };
}

// [2025-10-09] NEW: Simple local fallback backlog if no AI env is present
function localBacklog(description: string): AIBacklog {
  const name = description
    .slice(0, 60)
    .replace(/\.*$/, "")
    .trim() || "Generated Project";
  return {
    projectName: name,
    tasks: [
      {
        title: "Project setup and architecture",
        description:
          "Choose tech stack, init repo/CI, define architecture and coding standards.",
        type: "Task",
        priority: "High",
        labels: ["ai", "autogenerated"],
        storyPoints: 3,
        acceptanceCriteria: [
          "Repo initialized with CI",
          "Lint/format hooks configured",
          "Architecture document committed",
        ],
      },
      {
        title: "MVP feature breakdown",
        description:
          "Identify core MVP flows from the description and outline routes/screens/entities.",
        type: "Story",
        priority: "Highest",
        labels: ["ai", "autogenerated"],
        storyPoints: 5,
        acceptanceCriteria: [
          "List of MVP flows documented",
          "Rough UI/UX mock for main flow",
          "Data entities and relationships listed",
        ],
      },
      {
        title: "Testing & instrumentation baseline",
        description:
          "Set up unit tests, e2e test scaffold, error and analytics logging.",
        type: "Task",
        priority: "Medium",
        labels: ["ai", "autogenerated"],
        storyPoints: 3,
        acceptanceCriteria: [
          "Unit test runner in place",
          "E2E test scaffold exists",
          "Error logging visible in CI output",
        ],
      },
    ],
  };
}

// [2025-10-09] NEW: Try OpenAI JSON generation; fall back to localBacklog if anything fails
async function generateBacklogWithAI(description: string): Promise<AIBacklog> {
  if (!AI_ENDPOINT || !AI_KEY) {
    return localBacklog(description); // no AI config present
  }
// [2025-10-09] NEW: pick model from env, default to gpt-5
  const OPENAI_MODEL = Deno.env.get("OPENAI_MODEL") ?? "gpt-5"; // [2025-10-09] NEW

  // [2025-10-09] Safe URL builder: accept base (/v1) or full (/v1/chat/completions)
  const trimmed = AI_ENDPOINT.replace(/\/+$/, "");
  const url = /\/chat\/completions$/.test(trimmed) ? trimmed : `${trimmed}/chat/completions`; // [2025-10-09] NEW

  const baseBody = (model: string) => ({
    model,
    response_format: { type: "json_object" },
    messages: [
      {
        role: "system",
        content:
          "You are a project planning assistant. Return a JSON object with projectName and tasks[].",
      },
      {
        role: "user",
        content: `Create a backlog from this description. Return ONLY JSON:
${description}

JSON schema:
{
  "projectName": "string",
  "tasks": [
    {
      "title": "string",
      "description": "string",
      "type": "Task|Story|Bug",
      "priority": "Highest|High|Medium|Low",
      "labels": ["string"],
      "storyPoints": 1,
      "acceptanceCriteria": ["string"]
    }
  ]
}`,
      },
    ],
  });

  // [2025-10-09] Build headers and a variant-without-Project for retry
  const headersWithProject: Record<string, string> = {
    "Content-Type": "application/json",
    "Authorization": `Bearer ${AI_KEY}`,
  };
  if (OPENAI_PROJECT) headersWithProject["OpenAI-Project"] = OPENAI_PROJECT;

  const headersWithoutProject: Record<string, string> = {
    "Content-Type": "application/json",
    "Authorization": `Bearer ${AI_KEY}`,
  };

  // [2025-10-09] Helper to parse a chat completion into AIBacklog
  const parseCompletion = async (res: Response): Promise<AIBacklog> => {
    const json = await res.json();
    const content =
      json?.choices?.[0]?.message?.content ??
      json?.choices?.[0]?.message ??
      json?.choices?.[0]?.text ??
      "";
    try {
      const parsed = JSON.parse(content);
      if (parsed?.tasks && Array.isArray(parsed.tasks)) return parsed as AIBacklog;
      return localBacklog(description);
    } catch {
      return localBacklog(description);
    }
  };

  // [2025-10-09] Attempt 1: chosen model + (maybe) project header
  let res = await fetch(url, {
    method: "POST",
    headers: headersWithProject,
    body: JSON.stringify(baseBody(OPENAI_MODEL)),
  });

  if (res.ok) return await parseCompletion(res);

  // [2025-10-09] If model access / project header caused 403, retry WITHOUT project header
  if (res.status === 403) {
    try {
      const bodyText = await res.text();
      const isModelAccess =
        bodyText.includes("model_not_found") ||
        bodyText.includes("does not have access to model");
      if (isModelAccess && OPENAI_PROJECT) {
        console.warn("[AI] 403 with project header; retrying without OpenAI-Project…"); // [2025-10-09] NEW
        res = await fetch(url, {
          method: "POST",
          headers: headersWithoutProject, // no project header
          body: JSON.stringify(baseBody(OPENAI_MODEL)),
        });
        if (res.ok) return await parseCompletion(res);
      }
    } catch {
      // ignore parse errors and continue to next fallback
    }
  }

  // [2025-10-09] Attempt 2: fallback model (e.g., gpt-4o) WITHOUT project header
  const fallbackModel = "gpt-4o"; // adjust if your org uses another accessible model // [2025-10-09] NEW
  console.warn(`[AI] Falling back to model "${fallbackModel}" without project header…`); // [2025-10-09] NEW
  res = await fetch(url, {
    method: "POST",
    headers: headersWithoutProject,
    body: JSON.stringify(baseBody(fallbackModel)),
  });

  if (res.ok) return await parseCompletion(res);

  // [2025-10-09] Any remaining failure → local fallback
  try {
    const errTxt = await res.text();
    console.warn("[AI] OpenAI call failed; using local backlog. Last error:", errTxt);
  } catch {
    // ignore
  }
  return localBacklog(description);
}

// --- HTTP Handler -------------------------------------------------------------

const handler: Deno.ServeHandler = async (req) => {
  // Preflight
  if (req.method === "OPTIONS") {
    return new Response(null, { headers: corsHeaders() });
  }

  if (req.method !== "POST") {
    return new Response(JSON.stringify({ error: "Use POST with JSON payload" }), {
      status: 405,
      headers: { "Content-Type": "application/json", ...corsHeaders() },
    });
  }

  // Parse input
  let description = "";
  try {
    const payload = await req.json();
    description = String(payload?.description ?? "").trim();
  } catch {
    return new Response(JSON.stringify({ error: "Invalid JSON body" }), {
      status: 400,
      headers: { "Content-Type": "application/json", ...corsHeaders() },
    });
  }

  if (!description) {
    return new Response(JSON.stringify({ error: "Missing 'description' string" }), {
      status: 400,
      headers: { "Content-Type": "application/json", ...corsHeaders() },
    });
  }

  // Create backlog
  const backlog = await generateBacklogWithAI(description); // [2025-10-09] NEW: AI-first, fallback local

  return new Response(JSON.stringify(backlog), {
    status: 200,
    headers: { "Content-Type": "application/json", ...corsHeaders() },
  });
};

// --- Boot --------------------------------------------------------------------

serve(handler, { port: PORT }); // [2025-10-09] NEW: explicit port bind (defaults 8000)
